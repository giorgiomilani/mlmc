# -*- coding: utf-8 -*-
"""Multi-level Monte Carlo methods for option pricing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UZQwH79JTTGGy_syFb6p9TpdcbM9v306
"""

import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm  # Import the tqdm package for progress bar functionality

# Define constants for the problem
r = 0.05  # Risk-free interest rate
sigma = 0.2  # Volatility
S0 = 1  # Initial stock price
K = 1  # Strike price
T = 1  # Time to maturity

# Monte Carlo simulation parameters
M = 1000  # Number of time steps (1/h)
N = 100000  # Number of simulated paths

# Time step size
h = T / M  # Step size for discretization

# Pre-allocate storage for the payoffs
payoffs = np.zeros(N)  # Array to store the payoffs for each path

# Simulate N independent paths of the geometric Brownian motion
for n in tqdm(range(N), desc="Simulating Paths"):  # Add progress bar for the loop
    S = np.zeros(M + 1)  # Array to store the asset prices for a single path
    S[0] = S0  # Initial stock price

    # Simulate the path using the Euler-Maruyama scheme
    for m in range(M):
        # Brownian increment: dW ~ N(0, h)
        dW = np.random.normal(0, np.sqrt(h))
        # Update stock price using Euler-Maruyama scheme
        S[m + 1] = S[m] + r * S[m] * h + sigma * S[m] * dW

    # Approximate the arithmetic average price
    S_bar = h * np.sum((S[:-1] + S[1:]) / 2)

    # Compute the discounted payoff for the Asian option
    payoffs[n] = np.exp(-r) * max(0, S_bar - K)

# Estimate the expected payoff (option price)
option_price = np.mean(payoffs)

# Compute variance and bias-related measures
option_variance = np.var(payoffs, ddof=1)  # Sample variance of the payoffs
standard_error = np.sqrt(option_variance / N)  # Standard error of the mean

# Print results
print(f"Estimated Asian Option Price: {option_price:.4f}")
print(f"Standard Error: {standard_error:.4e}")
print(f"Variance of Payoffs: {option_variance:.4f}")

# Define a function to simulate geometric Brownian motion paths and compute option payoffs
def simulate_asian_option(S0, r, sigma, K, T, M, N):
    """
    Simulates the Asian option payoff using Monte Carlo for given discretization steps and paths.

    Parameters:
    S0 : float - Initial stock price
    r : float - Risk-free interest rate
    sigma : float - Volatility
    K : float - Strike price
    T : float - Time to maturity
    M : int - Number of time steps
    N : int - Number of simulated paths

    Returns:
    float - Estimated option price (Monte Carlo mean)
    """
    h = T / M  # Time step size
    payoffs = np.zeros(N)  # Pre-allocate payoffs array

    # Simulate N paths
    for n in tqdm(range(N), desc="Simulating paths"):  # Add progress bar for the path loop
        S = np.zeros(M + 1)  # Array for asset prices along a single path
        S[0] = S0  # Set initial stock price

        # Euler-Maruyama scheme for simulating GBM paths
        for m in range(M):
            dW = np.random.normal(0, np.sqrt(h))  # Brownian increment
            S[m + 1] = S[m] + r * S[m] * h + sigma * S[m] * dW  # Update stock price

        # Approximate the arithmetic average price
        S_bar = h * np.sum((S[:-1] + S[1:]) / 2)

        # Compute discounted payoff
        payoffs[n] = np.exp(-r) * max(0, S_bar - K)

    # Return the Monte Carlo estimate of the option price (mean payoff)
    return np.mean(payoffs)

# Bias analysis setup
M_coarse = 50  # Coarse step size (1/h)
M_fine = 100   # Finer step size (1/(2h))
N = 10000      # Number of paths (same for both cases)

# Compute Monte Carlo estimates for coarse and fine discretizations with progress
print("Computing coarse discretization...")
option_price_coarse = simulate_asian_option(S0, r, sigma, K, T, M_coarse, N)

print("Computing fine discretization...")
option_price_fine = simulate_asian_option(S0, r, sigma, K, T, M_fine, N)

# Compute the bias as the difference between coarse and fine estimates
bias = abs(option_price_coarse - option_price_fine)

# Print results
print(f"Option Price with Coarse Discretization (h): {option_price_coarse:.4f}")
print(f"Option Price with Fine Discretization (2h): {option_price_fine:.4f}")
print(f"Estimated Bias: {bias:.4e}")

# Function to investigate how bias scales with respect to h
def bias_scaling_analysis(S0, r, sigma, K, T, N, discretizations):
    """
    Analyzes how bias scales with respect to step size (h) using different discretizations.

    Parameters:
    S0 : float - Initial stock price
    r : float - Risk-free interest rate
    sigma : float - Volatility
    K : float - Strike price
    T : float - Time to maturity
    N : int - Number of simulated paths
    discretizations : list - List of M values (1/h) for different step sizes

    Returns:
    list - Option prices for different discretizations
    """
    option_prices = []

    for M in discretizations:
        # Compute the option price for the given discretization level
        option_price = simulate_asian_option(S0, r, sigma, K, T, M, N)
        option_prices.append(option_price)

    return option_prices

# Define different discretization levels (M values, corresponding to h = 1/M)
discretizations = [10, 100, 1000, 5000]  # Coarser to finer step sizes

# Perform bias scaling analysis
option_prices = bias_scaling_analysis(S0, r, sigma, K, T, N, discretizations)

# Compute step sizes (h) corresponding to each M
step_sizes = [T / M for M in discretizations]

# Print results
for h, price in zip(step_sizes, option_prices):
    print(f"Step size (h): {h:.4f}, Option Price: {price:.4f}")

# Reference price (assume the finest discretization gives the most accurate estimate)
reference_price = option_prices[-1]

# Compute bias for each step size
biases = [abs(price - reference_price) for price in option_prices]

# Plot step size vs. bias
plt.figure(figsize=(8, 6))
plt.loglog(step_sizes, biases, marker='o', label='Bias')
plt.xlabel('Step size (h)')
plt.ylabel('Bias')
plt.title('Bias Scaling with Step Size (h)')
plt.grid(True, which="both", linestyle="--", linewidth=0.5)
plt.legend()
plt.show()

def adaptive_mse_control(S0, r, sigma, K, T, epsilon, initial_M=10, max_iter=10):
    """
    Adaptive algorithm to estimate the option price satisfying MSE <= epsilon^2.

    Parameters:
    S0 : float - Initial stock price
    r : float - Risk-free interest rate
    sigma : float - Volatility
    K : float - Strike price
    T : float - Time to maturity
    epsilon : float - Target MSE tolerance
    initial_M : int - Initial number of time steps (coarsest level)
    max_iter : int - Maximum number of refinement iterations

    Returns:
    dict - Results containing the final estimate, step size, number of paths, and achieved MSE.
    """
    # Initial parameters
    M = initial_M  # Number of time steps (1/h)
    N = 1000  # Initial number of paths (arbitrary starting point)

    # Progress bar for the adaptive refinement process
    with tqdm(total=max_iter, desc="Adaptive Refinement") as pbar:
        for iteration in range(max_iter):
            # Step size (h) based on M
            h = T / M

            # Monte Carlo estimation for the current h and N
            option_price = simulate_asian_option(S0, r, sigma, K, T, M, N)

            # Bias estimation (using finer level 2M for comparison)
            option_price_finer = simulate_asian_option(S0, r, sigma, K, T, 2 * M, N)
            bias = abs(option_price - option_price_finer)

            # Variance estimation
            payoffs = np.zeros(N)
            for n in range(N):
                S = np.zeros(M + 1)
                S[0] = S0
                for m in range(M):
                    dW = np.random.normal(0, np.sqrt(h))
                    S[m + 1] = S[m] + r * S[m] * h + sigma * S[m] * dW
                S_bar = h * np.sum((S[:-1] + S[1:]) / 2)
                payoffs[n] = np.exp(-r) * max(0, S_bar - K)
            variance = np.var(payoffs, ddof=1)

            # MSE decomposition
            mse = bias**2 + variance / N

            # Update progress bar
            pbar.set_postfix({"MSE": mse, "Bias^2": bias**2, "Variance/N": variance / N})
            pbar.update(1)

            # Check if MSE is within the tolerance
            if mse <= epsilon**2:
                return {
                    "estimate": option_price,
                    "step_size": h,
                    "num_paths": N,
                    "mse": mse,
                    "bias": bias,
                    "variance": variance,
                }

            # Adjust parameters: refine h (increase M) or increase N based on the dominant term
            if bias**2 > variance / N:
                # Bias dominates: refine h by increasing M
                M *= 2
            else:
                # Variance dominates: increase N
                N *= 2

    # If the algorithm fails to converge within max_iter
    return {
        "estimate": option_price,
        "step_size": h,
        "num_paths": N,
        "mse": mse,
        "bias": bias,
        "variance": variance,
        "warning": "Max iterations reached. Convergence not achieved.",
    }

# Set target MSE tolerance
epsilon = 1e-3

# Run the adaptive algorithm
adaptive_results = adaptive_mse_control(S0, r, sigma, K, T, epsilon)

# Display results
for key, value in adaptive_results.items():
    print(f"{key}: {value}")

# Graph 1: Bias Scaling on Log-Log Scale (reusing earlier bias data)
reference_price = option_prices[-1]  # Finest step size as reference
biases = [abs(price - reference_price) for price in option_prices]

plt.figure(figsize=(8, 6))
plt.loglog(step_sizes, biases, marker='o', label='Bias')
plt.xlabel('Step size (h)', fontsize=12)
plt.ylabel('Bias', fontsize=12)
plt.title('Bias Scaling with Step Size (Log-Log Scale)', fontsize=14)
plt.grid(True, which="both", linestyle="--", linewidth=0.5)
plt.legend()
plt.show()

# Graph 2: MSE Decomposition
bias_squared = adaptive_results['bias'] ** 2
variance_term = adaptive_results['variance'] / adaptive_results['num_paths']
mse_contributions = [bias_squared, variance_term]

plt.figure(figsize=(8, 6))
plt.bar(['Bias^2', 'Variance/N'], mse_contributions, color=['blue', 'orange'])
plt.ylabel('Contribution to MSE', fontsize=12)
plt.title('MSE Decomposition', fontsize=14)
plt.grid(axis='y', linestyle='--', linewidth=0.5)
plt.show()

# Graph 3: Convergence of Estimates
# Simulate additional step sizes for demonstration
additional_discretizations = [10, 20, 50, 100, 200]
convergence_prices = bias_scaling_analysis(S0, r, sigma, K, T, N, additional_discretizations)

plt.figure(figsize=(8, 6))
plt.plot(additional_discretizations, convergence_prices, marker='o', linestyle='-', label='Option Price')
plt.xlabel('Number of Time Steps (M)', fontsize=12)
plt.ylabel('Option Price', fontsize=12)
plt.title('Convergence of Option Price with Finer Discretization', fontsize=14)
plt.grid(True)
plt.legend()
plt.show()

# Graph tep 4: Computational Cost vs. Accuracy
computational_costs = [N * M for M in discretizations]  # Cost proportional to paths * steps
plt.figure(figsize=(8, 6))
plt.plot(computational_costs, biases, marker='o', linestyle='-', label='Bias')
plt.xlabel('Computational Cost (N * M)', fontsize=12)
plt.ylabel('Bias', fontsize=12)
plt.title('Trade-Off: Computational Cost vs. Accuracy', fontsize=14)
plt.grid(True)
plt.legend()
plt.show()